{"title": "Machine Learning GPU Performance Engineer", "level": "Mid", "location": "London, UK", "description": "Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google\u2019s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.", "key_qualifications": "Bachelor's degree or equivalent practical experience. 5 years of experience with software development in one or more programming languages, and with data structures/algorithms. 3 years of experience testing, maintaining, or launching software products, and 1 year of experience with software design and architecture. 3 years of experience with performance, systems data analysis, visualization tools, or debugging.", "preferred_qualifications": "Master's degree or PhD in Computer Science or related technical field. 1 year of experience in a technical leadership role. Experience developing accessible technologies.", "responsibilities": "Identify and maintain LLM training and serving benchmarks that are representative to Google production, industry and ML community, use them to identify performance opportunities and drive XLA:GPU/Triton performance toward state-of-the-art, and to guide XLA releases. Engage with Google product teams such as Deepmind to solve their ML model performance problems, onboarding new LLM models and products on GPU hardware, enabling LLMs to train and serve efficiently on a very large scale (i.e., thousands of GPUs). Run architecture level simulations on GPU designs and perform roofline analysis to guide internal teams. Run performance benchmarks on GPU hardware using internal and external tools. Analyze performance and efficiency metrics to identify bottlenecks, design and implement solutions at Google fleetwide scale.", "company": "google", "url": "https://www.google.com/about/careers/applications/jobs/results/113217780018225862"}