{"title": "Traffic Pumping Abuse Analyst, Trust and Safety", "location": "Hyderabad, Telangana, India; Bengaluru, Karnataka, India", "level": "Mid", "description": "The Trust and Safety team has the critical responsibility of protecting Google's users by ensuring online safety by fighting fraud and abuse across Google products (e.g., Ads, Maps, Chrome, Play, Gmail, and Search). The Messaging Spam and Abuse team works on preventing abuse within the messaging ecosystem (i.e., xMS, RCS, RBM, Google Messages). In this role, you will work globally and cross-functionally with Google Engineers and Product Managers to navigate online safety situations and take on abuse and fraud at Google scale.", "key_qualifications": "Bachelor's degree or equivalent practical experience, 4 years of experience working on signal development, data analysis, cyber security, or anti-abuse, Experience with data analysis, tools and processes, and building customer reputation models", "preferred_qualifications": "Experience with fraud/abuse investigations, fraud risk management, security and threat analysis in the context of internet, telephony, or communication-related products, Experience working with complex engineering systems and processes, Experience in large-scale data analysis, tools and processes, and building customer reputation models, Knowledge of SMS/MMS/RCS or SIM/Phone Number fraud and abuse, Programming ability in one or more languages (e.g., Python, Golang), Excellent written and verbal communication and presentation skills to deliver findings to cross-functional partners, and ability to influence cross-functionally at various levels", "responsibilities": "Analyze SMS traffic trends to identify anomalies and investigate the underlying vulnerabilities and potential abuse. Build in-line protections such as quotas and targeted abuse rules leveraging reputation at all levels (i.e., phone number, user, IP etc.). Translate abuse protection requirements into data modeling initiatives and build prototypes. Work with engineering teams to put machine learning (ML) models and heuristic rules into production. Perform active threat monitoring, identify gaps in abuse detection, update abuse rules based on evolving patterns, perform quality checks to measure system/model reliability, and resolve false positives.", "company": "google", "url": "https://www.google.com/about/careers/applications/jobs/results/121672512999170758"}